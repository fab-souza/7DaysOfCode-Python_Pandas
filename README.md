# 7 Days Of Code - Python Pandas

![Badge em Desenvolvimento](http://img.shields.io/static/v1?label=STATUS&message=EM%20DESENVOLVIMENTO&color=GREEN&style=for-the-badge)

![Badge code size](https://img.shields.io/github/languages/code-size/fab-souza/7DaysOfCode-Python_Pandas)

| :placard: Vitrine.Dev |    |
| -------------  | --- |
| :sparkles: Nome        | **7 Days Of Code - Python Pandas**
| :label: Tecnologias | python
| :rocket: URL         | 
| :fire: Desafio     | [7 Days of Code - Python Pandas](https://7daysofcode.io/matricula/pandas)

![](https://user-images.githubusercontent.com/67301805/235231091-305c5353-564d-433b-a68b-e0bb2133546b.jpg#vitrinedev)

## Sobre o desafio üìö




## Minha pr√°tica üë©üèª‚Äçüíª

### Desafio 1: Importa√ß√£o dos dados

![01](https://user-images.githubusercontent.com/67301805/236515552-328963ef-a7ac-4239-8f8e-6ae3e68512f7.jpg)

- Unificar todos os dados dos empr√©stimos em um Dataset 

![image](https://user-images.githubusercontent.com/67301805/236516899-b6f8c069-3565-4fab-8f46-dd1128d36998.png)


- Mesclar com os dados do acervo

Para fazer uni√£o dos dois *dataset*, fiz alguns testes antes com os dados de 2020. Originalmente, ele possui 26.561 registros. Ao fazer a uni√£o atrav√©s do *inner*, fiquei com 25.610 registros, quase 1.000 a menos.

Com a uni√£o atrav√©s do *left*, o dataset ficou com 26.636 linhas, criando alguns dados.

J√° atrav√©s do *right*, o dataset passou 549.000 registros.

Diante o resultado destes testes, achei melhor fazer a uni√£o atrav√©s do *inner* e perder alguns registros, do que acabar criando dados.

![image](https://user-images.githubusercontent.com/67301805/236517323-d0e171a2-dc27-439d-9463-2e41d0efeb44.png)

- Fazer a limpeza

A limpeza b√°sica, refere-se a retirada de dados nulos e duplicados. Eu decidi manter os empr√©stimos que n√£o foram devolvidos, porque futuramente eles podem sinalizar quais s√£o os tipos de livros que est√£o mais propensos a n√£o serem devolvidos. J√° em rela√ß√£o aos dados duplicados, pensei em verificar se haviam dados repetidos no *id_emprestimo*, porque achei que cada empr√©stimo fosse √∫nico e se ele aparecesse mais de uma vez, seria um erro de registro, sistema, etc. 

Mas eu recordei da minha √©poca de faculdade, em que peguei emprestado mais de um livro de uma vez. Por exemplo, no mesmo dia que precisava do livro de C√°lculo I, eu tamb√©m tinha que ler sobre circuitos el√©tricos e acabava pegando mais de um livro. 

No caso da institui√ß√£o em que me graduei, cada aluno poderia pegar emprestado no m√°ximo 3 livros de uma vez. Se precisasse retirar mais livros, t√≠nhamos que devolver 1 dos 3 para pegar o outro, ou pedir para algu√©m fazer o empr√©stimo por voc√™. Ou seja, quando retirava mais de um livro da biblioteca, ambos estariam registrados sob o mesmo *id_emprestimo*.

Por√©m, ao contar as apari√ß√µes dos *ids*, vi que h√° empr√©stimos que aparecem mais do que 4 vezes: 

![image](https://user-images.githubusercontent.com/67301805/236517624-f902f0eb-9d3a-444d-b748-62e4e239c1bc.png)

Sem contar que achei muito estranho uma biblioteca permitir a retirada de 7 livros de uma s√≥ vez‚Ä¶ ü§î

Portanto, vou supor que a biblioteca da UFRN tamb√©m permite a retirada, de no m√°ximo, 3 livros por empr√©stimo para cada aluno.

Diante o resultado da contagem, tamb√©m fui verificar a vari√°vel *data_emprestimo* e ver quantas vezes cada data aparece.

![image](https://user-images.githubusercontent.com/67301805/236517804-5b6f18a5-8906-45cd-9dd3-df5fe749dc74.png)

Estranhamente, tamb√©m temos datas que aparecem 7 vezes no dataset.  

Para tirar minha d√∫vida se realmente houve erro no sistema e um registro acabou sendo duplicado, fiz uma *query* selecionando um dos *ids* repetidos:

![image](https://user-images.githubusercontent.com/67301805/236517917-c8cdd10e-2c3c-474a-b8cd-9c1c0f10bc67.png)

E de fato, eles se tratam de um erro, pois todos os registros referem-se √† retirada do mesmo livro. Fiz o mesmo para o pr√≥ximo *id* e houve o mesmo erro que aconteceu com o *id* anterior, nos 3 *ids* seguintes, retiraram mais de um livro de uma s√≥ vez, mas ocorreu a duplica√ß√£o do registro.
Diante estes erros, fiz um *drop_duplicate()*



### Desafio 2: Limpeza dos dados

![02](https://user-images.githubusercontent.com/67301805/236515560-9d6f3444-ed20-4ad7-a664-a88fdb9d4bd5.jpg)




### Desafio 3: An√°lise explorat√≥ria de dados e DateTime

![03](https://user-images.githubusercontent.com/67301805/236515558-983fef13-2c22-4a7a-92f4-a3ac7b7214ac.jpg)





### Desafio 4: An√°lise explorat√≥ria de dados e Vari√°veis

![04](https://user-images.githubusercontent.com/67301805/236515565-75209607-ed32-4899-a2e8-7ce7863965ca.jpg)


### Desafio 5: An√°lise explorat√≥ria de dados e Boxplot

![05](https://user-images.githubusercontent.com/67301805/236515568-af3baf59-6b27-4095-8403-f1a09c762bd6.jpg)


### Desafio 6: JSON, Excel e Pivot_table

![06](https://user-images.githubusercontent.com/67301805/236515569-49c276c0-6db8-4681-b67b-50c608fffd65.jpg)

### Desafio 7: Customiza√ß√£o de tabelas

![07](https://user-images.githubusercontent.com/67301805/236515573-e132a360-850a-4e67-ae96-a0f5c420ab9c.jpg)







## Ferramentas utilizadas üß∞
<p> <a href="https://www.python.org" target="_blank" rel="noreferrer"> <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/python/python-original.svg" alt="python" width="40" height="40"/> </a> 
    <a href="https://pandas.pydata.org/" target="_blank" rel="noreferrer"> <img src="https://raw.githubusercontent.com/devicons/devicon/2ae2a900d2f041da66e950e4d48052658d850630/icons/pandas/pandas-original.svg" alt="pandas" width="40" height="40"/> </a>
    <a href="https://seaborn.pydata.org/" target="_blank" rel="noreferrer"> <img src="https://seaborn.pydata.org/_images/logo-mark-lightbg.svg" alt="seaborn" width="40" height="40"/> </a>
    </p>
