# 7 Days Of Code - Python Pandas

![Badge em Desenvolvimento](http://img.shields.io/static/v1?label=STATUS&message=EM%20DESENVOLVIMENTO&color=GREEN&style=for-the-badge)

![Badge code size](https://img.shields.io/github/languages/code-size/fab-souza/7DaysOfCode-Python_Pandas)

| :placard: Vitrine.Dev |    |
| -------------  | --- |
| :sparkles: Nome        | **7 Days Of Code - Python Pandas**
| :label: Tecnologias | python
| :rocket: URL         | 
| :fire: Desafio     | [7 Days of Code - Python Pandas](https://7daysofcode.io/matricula/pandas)

![](https://user-images.githubusercontent.com/67301805/235231091-305c5353-564d-433b-a68b-e0bb2133546b.jpg#vitrinedev)

## Sobre o desafio üìö




## Minha pr√°tica üë©üèª‚Äçüíª

### Desafio 1: Importa√ß√£o dos dados

![01](https://user-images.githubusercontent.com/67301805/236515552-328963ef-a7ac-4239-8f8e-6ae3e68512f7.jpg)

- Unificar todos os dados dos empr√©stimos em um Dataset ‚úÖ 

![image](https://user-images.githubusercontent.com/67301805/236516899-b6f8c069-3565-4fab-8f46-dd1128d36998.png)


- Mesclar com os dados do acervo ‚úÖ

Para fazer uni√£o dos dois *dataset*, fiz alguns testes antes com os dados de 2020. Originalmente, ele possui 26.561 registros. Ao fazer a uni√£o atrav√©s do *inner*, fiquei com 25.610 registros, quase 1.000 a menos.

Com a uni√£o atrav√©s do *left*, o dataset ficou com 26.636 linhas, criando alguns dados.

J√° atrav√©s do *right*, o dataset passou 549.000 registros.

Diante o resultado destes testes, achei melhor fazer a uni√£o atrav√©s do *inner* e perder alguns registros, do que acabar criando dados.

![image](https://user-images.githubusercontent.com/67301805/236517323-d0e171a2-dc27-439d-9463-2e41d0efeb44.png)

- Fazer a limpeza ‚úÖ

A limpeza b√°sica, refere-se a retirada de dados nulos e duplicados. Eu decidi manter os empr√©stimos que n√£o foram devolvidos, porque futuramente eles podem sinalizar quais s√£o os tipos de livros que est√£o mais propensos a n√£o serem devolvidos. J√° em rela√ß√£o aos dados duplicados, pensei em verificar se haviam dados repetidos no *id_emprestimo*, porque achei que cada empr√©stimo fosse √∫nico e se ele aparecesse mais de uma vez, seria um erro de registro, sistema, etc. 

Mas eu recordei da minha √©poca de faculdade, em que peguei emprestado mais de um livro de uma vez. Por exemplo, no mesmo dia que precisava do livro de C√°lculo I, eu tamb√©m tinha que ler sobre circuitos el√©tricos e acabava pegando mais de um livro. 

No caso da institui√ß√£o em que me graduei, cada aluno poderia pegar emprestado no m√°ximo 3 livros de uma vez. Se precisasse retirar mais livros, t√≠nhamos que devolver 1 dos 3 para pegar o outro, ou pedir para algu√©m fazer o empr√©stimo por voc√™. Ou seja, quando retirava mais de um livro da biblioteca, ambos estariam registrados sob o mesmo *id_emprestimo*.

Por√©m, ao contar as apari√ß√µes dos *ids*, vi que h√° empr√©stimos que aparecem mais do que 4 vezes: 

![image](https://user-images.githubusercontent.com/67301805/236517624-f902f0eb-9d3a-444d-b748-62e4e239c1bc.png)

Sem contar que achei muito estranho uma biblioteca permitir a retirada de 7 livros de uma s√≥ vez‚Ä¶ ü§î

Portanto, vou supor que a biblioteca da UFRN tamb√©m permite a retirada, de no m√°ximo, 3 livros por empr√©stimo para cada aluno.

Diante o resultado da contagem, tamb√©m fui verificar a vari√°vel *data_emprestimo* e ver quantas vezes cada data aparece.

![image](https://user-images.githubusercontent.com/67301805/236517804-5b6f18a5-8906-45cd-9dd3-df5fe749dc74.png)

Estranhamente, tamb√©m temos datas que aparecem 7 vezes no dataset.  

Para tirar minha d√∫vida se realmente houve erro no sistema e um registro acabou sendo duplicado, fiz uma *query* selecionando um dos *ids* repetidos:

![image](https://user-images.githubusercontent.com/67301805/236517917-c8cdd10e-2c3c-474a-b8cd-9c1c0f10bc67.png)

E de fato, eles se tratam de um erro, pois todos os registros referem-se √† retirada do mesmo livro. Fiz o mesmo para o pr√≥ximo *id* e houve o mesmo erro que aconteceu com o *id* anterior, nos 3 *ids* seguintes, retiraram mais de um livro de uma s√≥ vez, mas ocorreu a duplica√ß√£o do registro.
Diante estes erros, fiz um *drop_duplicate()*



### Desafio 2: Limpeza dos dados

![02](https://user-images.githubusercontent.com/67301805/236515560-9d6f3444-ed20-4ad7-a664-a88fdb9d4bd5.jpg)

- Atribuir CDU ‚úÖ

Ao inv√©s de fazer o mapeamento do CDU atrav√©s de uma l√≥gica condicional, eu preferi utilizar a fun√ß√£o *pd.cut()*, que aprendi no 1¬∫ curso de estat√≠stica da Alura. A diferen√ßa √© que precisei definir, previamente, os *bins* e *labels* antes de utilizar a fun√ß√£o. Os *bins* s√£o os valores na lista *cdu* que limitam os valores para os *labels*, que s√£o as √°reas de conhecimento.

Para ter certeza que a classifica√ß√£o foi feita corretamente, fiz um *query()* selecionando alguns valores:

![image](https://user-images.githubusercontent.com/67301805/236519212-70ef2d2f-1329-4f3e-9fc2-683e78e921ba.png)

- Excluir coluna ‚úÖ

Segundo o Desafio, n√£o iria precisar da coluna *registro_sistema* em nenhum momento, por isso era melhor exclu√≠-la.

![image](https://user-images.githubusercontent.com/67301805/236519367-5de074db-2c76-4383-8c7e-eca4c9e690e4.png)

- Mudar tipo de vari√°vel ‚úÖ

Eu j√° havia realizado um pequeno tratamento nos dados, no dia anterior. Por exemplo al√©m de mudar a vari√°vel *matricula_ou_siape* para o tipo *string*, eu tamb√©m passei as vari√°veis referentes a datas para o tipo *datetime*, pois imaginei que, em algum momento, teria que fazer alguma an√°lise referente ao tempo.



### Desafio 3: An√°lise explorat√≥ria de dados e DateTime

![03](https://user-images.githubusercontent.com/67301805/236515558-983fef13-2c22-4a7a-92f4-a3ac7b7214ac.jpg)

- Analisar os empr√©stimos ‚úÖ

    - A quantidade que ocorreu no per√≠odo:
    
        Para ver quantos empr√©stimos ocorreram, fiz um *value_counts()* dos *id_emprestimo*. Sei que seu principal objetivo √© apresentar quantas vezes os itens aparecem ao longo do dataset, por√©m, ao final, ele tamb√©m mostra o total de valores √∫nicos.
        
        ![len](https://user-images.githubusercontent.com/67301805/236521550-5fdafa15-4ddf-46df-9912-2e26c1bc1038.jpg)

        Entretanto, um ponto chamou minha aten√ß√£o. Ao analisar o *id* que mais apareceu, no come√ßo, imaginei que a regra de empr√©stimo desta biblioteca fosse diferente da institui√ß√£o em que estudei, porque pensei que um aluno pegou 6 livros de uma s√≥ vez. 

        ![id](https://user-images.githubusercontent.com/67301805/236521214-af36e87d-4fca-4a2b-80b5-d8f83c2a2f13.jpg)

        Depois, pensei que tivesse ocorrido um erro no sistema, porque o *id dos exemplares* se repetiam. Ou seja, o aluno retirou 3 livros, s√≥ que, por algum motivo, o sistema acabou duplicando o empr√©stimo.

        ![rep](https://user-images.githubusercontent.com/67301805/236521833-332e4297-e48e-45ab-b04d-1c729bdaf349.jpg)

        No entanto, as datas do empr√©stimo s√£o diferentes, apenas o ano, para ser mais exata. H√° um intervalo de 1 ano entre a data dos empr√©stimos e devolu√ß√£o, por isso estes registros n√£o foram exclu√≠dos quando fiz a retirada de dados duplicados. 

        ![data](https://user-images.githubusercontent.com/67301805/236522335-78cb88ed-6ddc-40d1-8949-8c26f611be8e.jpg)

        Achei estranho ter dois empr√©stimos, feitos em anos diferentes, terem o mesmo *ID*. Se eu estivesse trabalhando (de forma remunerada) e me deparasse com uma situa√ß√£o como esta, eu definitivamente, pediria ajuda/concelho para os demais membros da equipe, porque acredito que a repeti√ß√£o de *ID dos empr√©stimos* seja algo que n√£o devesse ocorrer.

        Voltando √† an√°lise da quantidade de empr√©stimos que foram feitos, h√° uma outra forma de obter este valor. Para ver os itens √∫nico presentes em uma vari√°vel, eu uso o *.unique()*, que devolve um *array* com este valores. Ao aplicar a fun√ß√£o *len()* no *array*, ela me devolve o n√∫mero de itens, que no caso √© de 1955945 empr√©stimos.

    - Exemplar mais emprestado:
    
        Neste caso, utilizei o *value_counts()* na vari√°vel *c√≥digo de barra*. Ao fazer um *query()* dos tr√™s primeiros itens, vi que o segundo exemplar mais emprestado √© sobre Ci√™ncias Sociais, enquanto o primeiro e terceiro mais emprestado s√£o de Ci√™ncias Aplicadas.

        ![image](https://user-images.githubusercontent.com/67301805/236522989-07fd4290-9065-4838-9769-c132d895a367.png)
        ![image](https://user-images.githubusercontent.com/67301805/236523094-4d2794aa-e023-4e38-84af-d35faa771949.png)

- Verificar os empr√©stimos ao longo do tempo ‚úÖ

As datas no *dataset* s√£o compostas pelo dia e hora do empr√©stimo e antes de fazer a an√°lise, precisei separar estas duas informa√ß√µes. Segundo a interpreta√ß√£o que tive do Desafio, eu teria que fazer o somat√≥rio de quantos empr√©stimos que ocorreram no dia, antes de plotar o gr√°fico.

Ent√£o, peguei a vari√°vel *data_emprestimo* e fiquei apenas com os dias, ao usar o *dt.date*

![image](https://user-images.githubusercontent.com/67301805/236523293-2f085d0f-aba5-4ccd-966e-41d0c989423f.png)

Para saber quantas vezes aquela data aparece, fiz um *value_counts()* em cima do resultado anterior.

![image](https://user-images.githubusercontent.com/67301805/236523410-629da477-7bcc-4b88-ba49-47bb0d0fff1d.png)

Para ter uma ideia inicial de como estavam os empr√©stimos, fiz um gr√°fico com o *Matplotlib*:

![image](https://user-images.githubusercontent.com/67301805/236523514-b3acbe96-bbaa-4702-bd7d-cc4e370b3b75.png)

Para conseguir plotar um gr√°fico mais elaborado, peguei o resultado anterior e transformei em um *DataFrame* para facilitar o plot do gr√°fico com o *Seaborn*.

![image](https://user-images.githubusercontent.com/67301805/236523682-35f00235-0dbf-45a2-9563-b6066b92ed71.png)

Neste gr√°fico √© poss√≠vel observar melhor que nos per√≠odos de f√©rias (janeiro, julho e dezembro) a quantidade de empr√©stimo √© menor, enquanto houve uma maior busca pelos livros um pouco depois das f√©rias.

- Verificar os empr√©stimos ao longo dos anos ‚úÖ

Para saber como os empr√©stimos est√£o distribu√≠dos ao longo dos anos, peguei a vari√°vel *data_empr√©stimo*, apliquei o *dt.year*, para que ele me devolvesse apenas os anos das datas de empr√©stimo, e transformei o resultado em um DataFrame. Nele, √© poss√≠vel observar que o ano de 2020 teve a melhor quantidade de empr√©stimo, mas devo ressaltar que quando fiz a importa√ß√£o dos dados, s√≥ tive acesso ao come√ßo daquele ano. Sem contar que, foi um per√≠odo de pandemia, isolamento social e, provavelmente, sem acesso √† biblioteca. Os anos que tiveram mais empr√©stimos foram 2013, 2012 e 2014, respectivamente, e plotei um gr√°fico para facilitar a visualiza√ß√£o.

![image](https://user-images.githubusercontent.com/67301805/236523935-37a238ba-dddb-4b32-9b3d-86ec424de654.png)

O grande volume de empr√©stimo pode ter ocorrido por alguns motivos:

   - a institui√ß√£o come√ßou a oferecer mais cursos, ou ampliou a quantidade de salas/alunos por curso, que acabou ampliando o n√∫mero de pessoas atendidas pela biblioteca;
   - amplia√ß√£o do acervo, permitindo que mais alunos efetuassem o empr√©stimo.

Em 2015 e 2016, houve uma redu√ß√£o pela procura dos livros, que voltou a aumentar um pouco em 2017, mas n√£o houve melhora nos anos seguintes. A redu√ß√£o no volume de empr√©stimos pode ser um reflexo de como estava a economia do pa√≠s naquela √©poca, por exemplo, em 2015 eu estava estudando em uma institui√ß√£o p√∫blica, que passou por greves naquele ano, que bagun√ßou a grade curricular at√© 2016. Isso desestimulou alunos, que acabaram trancando a faculdade. Sem contar os casos em que o aluno parou de estudar, porque a situa√ß√£o financeira n√£o estava favor√°vel. 

Outro ponto que pode ter contribu√≠do para a redu√ß√£o, √© a maior circula√ß√£o de material digital (n√£o oficial) entre os alunos. 

- Qual m√™s possui menor n√∫mero de empr√©stimo? Os meses mais movimentados da biblioteca s√£o em mar√ßo e setembro? ‚úÖ

Para saber como os empr√©stimos est√£o distribu√≠dos ao longo dos meses, fiz algo semelhante ao que j√° tinha feito, por√©m mudei apenas o final do *.dt* para *.dt.month*. Tamb√©m transformei em um *DataFrame* e plotei um gr√°fico.

![image](https://user-images.githubusercontent.com/67301805/236524225-9662f8c4-d38f-4c3d-b5a1-219bc3ddd210.png)

E de fato, os meses com menor procura s√£o durante as f√©rias de ver√£o e inverno, janeiro-dezembro e junho-julho, respectivamente. J√° os meses com maior procura s√£o mar√ßo e agosto, diferente da suspeita interna, setembro n√£o √© um dos 2 meses com maior procura.

- Qual hor√°rio possui maior movimento? ‚úÖ

Para finalizar com a distribui√ß√£o ao longo das horas, mudei o *.dt* para *.dt.hour*, transformei o resultado em um *DataFrame* e plotei o gr√°fico.

![image](https://user-images.githubusercontent.com/67301805/236524390-79fb5b23-4ad4-4d2e-9be4-87b6300cd898.png)

Na parte da manh√£, 10 e 11 horas possuem o maior movimento, na parte da tarde das 16 √†s 18 horas h√° um grande movimento na biblioteca, enquanto na parte da noite √†s 20 horas √© o hor√°rio mais movimentado. Em contrapartida, os hor√°rios com menor movimento s√£o √†s 6, √†s 22, 23 e √† meia-noite. 

Diante estes n√∫meros, eu suspenderia o atendimento ao usu√°rio √†s 6 da manh√£, √†s 23h e a meia-noite, porque de 2010 at√© 2020 (mesmo que parcial) estes 3 hor√°rios tiveram um total de 82 empr√©stimos, que quando comparados com os mais de 2 milh√µes de registros que estamos analisando, n√£o chega a atingir 0,01% do total. Ou seja, s√£o os melhores hor√°rios para se dedicar a outras atividades. Enquanto √†s 10 e 11h da manh√£ e das 16 √†s 19h, o ideal seria focar no atendimento ao p√∫blico.



### Desafio 4: An√°lise explorat√≥ria de dados e Vari√°veis

![04](https://user-images.githubusercontent.com/67301805/236515565-75209607-ed32-4899-a2e8-7ce7863965ca.jpg)

- Tipo de v√≠nculo ‚úÖ

Para saber os valores √∫nicos e quantas vezes eles aparecem na vari√°vel, eu utilizei o *value_counts()*, que me devolveu uma *Series* mostrando que os alunos de gradua√ß√£o s√£o os maiores consumidores das bibliotecas, seguidos pelos alunos de p√≥s-gradua√ß√£o e docentes. O que faz total sentido, j√° que estamos analisando dados de um setor da UFRN, ter pessoas que fazem parte do meio acad√™mico como maiores consumidores √© compreens√≠vel.

![image](https://user-images.githubusercontent.com/67301805/236525687-5a95d499-0a16-4c5e-aa0e-4b5bb48c4bd2.png)

Para facilitar a compreens√£o do tamanho que estes p√∫blicos ocupam, tamb√©m fiz um *value_counts()* na forma de porcentagem. Alunos de gradua√ß√£o representam mais do que 75% dos usu√°rios, alunos de p√≥s-gradua√ß√£o s√£o quase 15%, enquanto docentes s√£o quase 3,5% do p√∫blico atendido.

![image](https://user-images.githubusercontent.com/67301805/236525780-c0fb3e3e-ce06-4bea-81fb-dd75ad711bda.png)

Depois, uni as duas *Series* em um *Dataframe* atrav√©s de uma fun√ß√£o que criei.

![image](https://user-images.githubusercontent.com/67301805/236525924-468059d3-5447-4850-9c76-4c816b943d64.png)

O ponto que me chamou aten√ß√£o, foi ver que servidores t√©cnico/administrativo e alunos do ensino m√©dio/t√©cnico efetuam mais empr√©stimos do que docentes e usu√°rios externos.  Investir nos p√∫blicos externos pode fazer com que eles frequentem mais as instala√ß√µes da universidade e quem sabe, futuramente, retornem como estudantes de gradua√ß√£o, p√≥s-gradua√ß√£o ou docentes. Ou seja, trazer a comunidade para a academia, mostrar que o investimento na universidade retorna na forma de pesquisa, inova√ß√£o cient√≠fica e benef√≠cios para a sociedade.

- Cole√ß√£o ‚úÖ

Considerando que repetiria as mesmas etapas para analisar as demais vari√°veis categ√≥ricas, eu criei fun√ß√µes que me devolveriam as *Series* e tabela. No caso das *Cole√ß√µes*, mais do que 99% dela √© composta pelo *Acervo circulante*, mas o p√∫blico tamb√©m acesso a *Multimeios* (que podem ser partituras, VHS, CDs, DVDs, etc. Fonte: [UFU](https://bibliotecas.ufu.br/servicos/multimeios)), *Monografias*, *Disserta√ß√µes* e demais publica√ß√µes.

![image](https://user-images.githubusercontent.com/67301805/236526211-66b42903-adda-473b-8456-7bdf58a949bc.png)

Para entender como p√∫blico consome as cole√ß√µes dispon√≠veis na biblioteca, fiz um *crosstab()* entre estas duas vari√°veis. Considerando o volume que o *Acervo circulante* representa, n√£o √© de espantar que ela seja a mais consumida por todos os p√∫blicos da biblioteca.

![image](https://user-images.githubusercontent.com/67301805/236526306-9568261e-aee2-4348-9b55-79ce9a08626b.png)

- Biblioteca ‚úÖ

J√° na vari√°vel *biblioteca*, temos 22 bibliotecas registradas, a que mais aparece √© a *Biblioteca Central Zila Mamede*, representando mais do que 68% dos empr√©stimos, enquanto a *Biblioteca Setorial do N√∫cleo de Ensino Superior do Agreste* √© a menor. Essa diferen√ßa pode ocorrer por motivos como:
    - A primeira biblioteca ser mais antiga e ter um acervo maior;
    
    - A biblioteca Central pode estar pr√≥xima a um campus que oferece mais cursos, enquanto a segunda atende alunos e docentes de alguns cursos;
    
    - A biblioteca do n√∫cleo de Ensino pode ter uma localiza√ß√£o mais afastada, enquanto a biblioteca Central ocupa um ponto com maior fluxo de pessoas.

![image](https://user-images.githubusercontent.com/67301805/236526490-47ca8c37-deb2-42ac-8ad3-7c0aaca39ec7.png)

Ao fazer um *crosstab* entre os usu√°rios e as bibliotecas, com exce√ß√£o da biblioteca Central Zila Mamede, ficou dif√≠cil identificar a distribui√ß√£o do p√∫blico. Por isso, tamb√©m fiz um *crosstab* com as porcentagens. 

Nela ficou mais f√°cil identificar alguns pontos, por exemplo, os alunos de gradua√ß√£o, depois da biblioteca Central, que representa 55,07% do total de empr√©stimos, utilizam bastante as bibliotecas voltadas a Ci√™ncias da Sa√∫de, a biblioteca Setorial do Centro Ci√™ncias da Sa√∫de e a biblioteca Setorial da Faculdade de Ci√™ncias da Sa√∫de do Trairi, representando 5,01% e 3,32% respectivamente. Estas porcentagem podem promover uma pesquisa mais aprofundada, ao buscar entender o que faz os alunos procurarem estes locais:

    - Melhores instala√ß√µes?
    
    - Material mais atualizado/novo?
    
    - Acesso mais r√°pido/f√°cil?
    
    - H√° cursos de medicina por perto?
    
J√° para os alunos de p√≥s-gradua√ß√£o, novamente, depois da biblioteca Central com seus 10,46%, h√° uma maior procura pela biblioteca Setorial do Centro de Ci√™ncias Humanas, Letras e Artes, seguida pela biblioteca Setorial Prof. Alberto Moreira Campos - Departamento de Odontologia, representando 0,92% e 0,65% respectivamente. Por se tratarem de 2 √°reas distintas, as campanhas voltadas para este p√∫blico podem ser divididas por √°reas, por exemplo promover eventos de humanas, exatas ou biol√≥gicas nas datas comemorativas de cada uma.

![image](https://user-images.githubusercontent.com/67301805/236527039-42c30129-7f2f-4ef3-a4c1-34a7734f72fa.png)

- CDU ‚úÖ

Em rela√ß√£o ao CDU, vemos que as bibliotecas efetuaram mais empr√©stimos de materiais sobre *Ci√™ncias aplicadas*, seguida por *Ci√™ncias sociais* e depois por *Matem√°tica e ci√™ncias naturais*, representando 68,78% 17,83% e 3,32% respectivamente. 

![image](https://user-images.githubusercontent.com/67301805/236527184-960a1bb2-61c0-4efb-9725-aeb4c8515fc4.png)

Ao analisar o *crosstab* dos usu√°rios com o CDU, √© poss√≠vel observar que estas tr√™s √°reas s√£o as mais procuradas pelos alunos de gradua√ß√£o, p√≥s-gradua√ß√£o, m√©dio/t√©cnico, docentes e servidores. Enquanto os docentes externos buscam mais materiais de *Ci√™ncias sociais* do que *Ci√™ncias aplicadas* e com esta informa√ß√£o podemos levantar algumas hip√≥teses, por exemplo:

    - As bibliotecas da UFRN possuem materiais melhores do que as outras institui√ß√µes;
    
    - Os docentes externos procuram a UFRN, porque elas t√™m um acesso mais f√°cil para eles, seja por quest√µes ligadas √† localiza√ß√£o, acesso ou hor√°rio de atendimento.

- Como se distribuem os empr√©stimos de exemplares pelos tipos de v√≠nculo dos usu√°rios? ‚úÖ

    Desta forma, a diretoria poder√° entender qual √© o p√∫blico que est√° utilizando a biblioteca e assim tomar decis√µes em continuar com a estrat√©gia de neg√≥cio atual ou modific√°-la.

- Quais cole√ß√µes s√£o mais emprestadas? ‚úÖ 

    Da mesma forma, as cole√ß√µes. Ranquear as cole√ß√µes mais emprestadas pelo p√∫blico, ser√° bastante importante para a estrat√©gia atual.

- Quais s√£o as bibliotecas com mais ou menos quantidade de empr√©stimos? ‚úÖ

    Assim, a diretoria conseguir√° entender onde ela dever√° melhorar e focar suas iniciativas.

- De quais temas da CDU s√£o os exemplares emprestados?
	
	Alunos de Gradua√ß√£o, P√≥s-gradua√ß√£o, do ensino m√©dio/t√©cnico, docentes, servidores, usu√°rios externos e ‚Äòoutros‚Äô pegam mais livros de Ci√™ncias aplicadas enquanto docentes externos emprestam mais livros de Ci√™ncias Sociais. Estas duas categorias representam mais do que 85% do acervo, ent√£o √© compreens√≠vel que elas ocupem as primeiras posi√ß√µes.


### Desafio 5: An√°lise explorat√≥ria de dados e Boxplot

![05](https://user-images.githubusercontent.com/67301805/236515568-af3baf59-6b27-4095-8403-f1a09c762bd6.jpg)

- Analisar separadamente os alunos de gradua√ß√£o e p√≥s-gradua√ß√£o ‚úÖ

Para fazer esta separa√ß√£o, utilizei um *query()* e criei um *DataFrame* para cada p√∫blico.

- Verificar quais cole√ß√µes possuem maior frequ√™ncia de empr√©stimo nos dois p√∫blicos ‚úÖ

Eu j√° tinha feito uma r√°pida an√°lise sobre isso no desafio anterior, quando fiz o *crosstab()* entre os usu√°rios e as cole√ß√µes. Neste caso, fiz um *value_counts()* das cole√ß√µes em cada *dataset*. Vemos que em ambos os casos, os materiais que mais foram emprestados pertencem ao *Acervo circulante*.

![image](https://user-images.githubusercontent.com/67301805/236532904-9930d383-7ada-4a3f-8201-82a5e19dcb57.png)
![image](https://user-images.githubusercontent.com/67301805/236532995-b25d5593-fe53-453f-b391-010ce8d4a5a8.png)

- Verificar a distribui√ß√£o dos empr√©stimos, mensais por ano, nos dois p√∫blicos ‚úÖ

Inicialmente, eu fiquei na d√∫vida sobre o que esta parte do desafio estava propondo. Eu havia entendido que deveria fazer um box-plot para cada, ou seja, os empr√©stimos estariam no eixo *y*, enquanto os meses estariam dispostos ao longo do eixo *x*. 

No terceiro desafio, manipulei as datas com o *dt.year* e *dt.month* para devolverem os anos e meses que os empr√©stimos ocorreram. Neste caso, utilizei estes atributos para criarem novas colunas no *dataset* de cada p√∫blico, o *Ano* e *Mes*.

![image](https://user-images.githubusercontent.com/67301805/236533277-8400fe4f-24ca-4443-9328-f8ff0a5f35f7.png)

Lembrando que cada linha do *dataset* representa o empr√©stimo de um √∫nico livro, por isso fiz um *value_counts()* das duas colunas que acabei de criar e transformei o resultado em um *DataFrame*

![image](https://user-images.githubusercontent.com/67301805/236533508-06508d0c-6780-4c9d-9c21-beb4c127c7d8.png)

- Plotar um box-plot para cada ano nos dois p√∫blicos ‚úÖ

Na hora de fazer o *box-plot*, entendi que n√£o daria certo fazer um para cada ano e que o correto seria colocar os **Anos** no eixo *x*.

![image](https://user-images.githubusercontent.com/67301805/236533618-9388de29-b537-4493-a785-462f8ceb7e19.png)

- O que ocorreu ao longo do tempo? ‚úÖ

No *box-plot* dos alunos de gradua√ß√£o, √© poss√≠vel identificar uma similaridade com o gr√°fico de linha feito no Desafio 3, j√° que estamos analisando o maior p√∫blico, consumindo a maior categoria presente nas bibliotecas. Ou seja, at√© 2013 os empr√©stimos estavam em uma crescente. 2014 e 2015 foram anos de baixa, houve uma recupera√ß√£o nos dois anos seguintes, at√© que em 2018 o volume de empr√©stimos teve nova queda.

![image](https://user-images.githubusercontent.com/67301805/236533777-705fa7f0-339a-4d92-a174-a4a9ef819b9a.png)

J√° para os alunos de p√≥s-gradua√ß√£o, temos um cen√°rio que difere um pouco do p√∫blico anterior. H√° a crescente de 2010 at√© 2013, por√©m entre 2013 √† 2017 os valores m√≠nimos e medianas est√£o pr√≥ximos uns dos outros, sem a queda dos empr√©stimos em 2014 e 2015, que observamos anteriormente. Este p√∫blico come√ßou a reduzir o n√∫mero de empr√©stimos em 2018, que seguiu em queda at√© 2020. 

![image](https://user-images.githubusercontent.com/67301805/236533863-7cf135aa-ad8f-410e-bd51-8625b64e047c.png)

Fica como sugest√£o para a diretoria da biblioteca:

 * rever o que foi feito entre 2010 e 2013, pois houve aumento do n√∫mero de empr√©stimos nestes anos.

 * Verificar se houve grandes mudan√ßas no n√∫mero de alunos, principalmente os alunos de gradua√ß√£o, j√° que em 2014 e 2015 ocorreram queda no n√∫mero total de empr√©stimos, mas isso n√£o ocorreu com os alunos de p√≥s-gradua√ß√£o. 
    
 * Rever as campanhas que foram promovidas, para os alunos de p√≥s-gradua√ß√£o, entre 2013 √† 2017, pois podemos inferir que elas foram consistentes, j√° que elas mantiveram as medianas do n√∫mero de empr√©stimos pr√≥ximos e com os maiores valores m√°ximos.


### Desafio 6: JSON, Excel e Pivot_table

![06](https://user-images.githubusercontent.com/67301805/236515569-49c276c0-6db8-4681-b67b-50c608fffd65.jpg)

- Extrair dados de arquivos Excel e JSON ‚úÖ

Para fazer a leitura do arquivo Excel, utilizei o *pd.read_excel*. Retirei a primeira linha, porque ela n√£o referente a vari√°veis e alterei os nomes das colunas, para ficarem iguais √†s vari√°veis presente no dataset sobre os empr√©stimos. 

J√° para ler o arquivo JSON, utilizei o *pd.read_json*, que me devolveu um dataset com duas linhas, a primeira referente aos alunos de gradua√ß√£o e a segunda, dos alunos de p√≥s-gradua√ß√£o.

![image](https://user-images.githubusercontent.com/67301805/236535034-22579cbf-ec52-406b-83d0-159e8c01b103.png)

O p√∫blico alvo desta an√°lise s√£o os alunos de gradua√ß√£o, ent√£o peguei somente as informa√ß√µes da primeira linha.

![image](https://user-images.githubusercontent.com/67301805/236535156-1deaec19-2d1c-4e32-a914-5fe551cec8d3.png)

Antes de fazer o agrupamento dos arquivos, vi que as matr√≠culas extra√≠das do arquivo Excel e JSON n√£o estavam no mesmo padr√£o. No Excel, elas estavam como *string*, enquanto no JSON elas estavam como *int64*. Eu n√£o poderia fazer somente a mudan√ßa para *string*, porque as matr√≠culas no Excel terminam com um *.0*. A resolu√ß√£o que encontrei foi fazer duas altera√ß√µes: *int* -> *float* -> *string*

![image](https://user-images.githubusercontent.com/67301805/236535250-2d6c3d1d-1f87-48af-981f-cdc7734e67f7.png)

- Agrupar os arquivos em um ‚úÖ

Os dados extra√≠dos do Excel resultaram em dataset com 10.000 linhas, enquanto os dados do arquivo JSON resultou em 62.802 linhas, uni ambos atrav√©s de um *pd.concat*.

![image](https://user-images.githubusercontent.com/67301805/236535445-e586a10d-f58b-45b4-b66f-a89d2ad03680.png)

- Calcular a quantidade de empr√©stimos feitos entre 2015 e 2020, pelos cursos: ‚úÖ

    - Biblioteconomia
    - Ci√™ncias sociais
    - Comunica√ß√£o social
    - Direito
    - Filosofia
    - Pedagogia

Antes de separar apenas os cursos solicitados, importei o dataset dos empr√©stimos, que estava trabalhando at√© ent√£o e fui fazendo recortes: Primeiro selecionando apenas os alunos de gradua√ß√£o, depois os empr√©stimos depois de 2015 e fiz o *reset* dos √≠ndices.

![image](https://user-images.githubusercontent.com/67301805/236535715-15e9578c-a17c-4a46-86ae-e6fbd52a89f4.png)

Antes de selecionar os cursos, fiz um *value_counts()*, para ter certeza de que eles est√£o presentes no dataset. Com a presen√ßa de todos confirmada, fiz um *.query()* selecion√°-los e criar um novo dataset.

![image](https://user-images.githubusercontent.com/67301805/236535799-0f35b4a9-2872-48b9-93de-d98c3a892a29.png)

Antes de fazer a uni√£o dos dois datasets, percebi que s√≥ precisaria de algumas vari√°veis do dataset dos empr√©stimos, a data do empr√©stimo e do n√∫mero de matr√≠cula do aluno. Ent√£o, fiz um *.loc* selecionando as duas vari√°veis e fiz a jun√ß√£o dos datasets com o *.merge*:

![image](https://user-images.githubusercontent.com/67301805/236535996-4c90569a-5d1a-4d20-97c2-708491babdd6.png)

Considerando que somente os anos que os empr√©stimos ocorreram importa nesta an√°lise, utilizei o *dt.year* na vari√°vel referente √†s datas de empr√©stimo para retirar as demais informa√ß√µes que n√£o s√£o sobre o ano.

Com a data alterada, fiz um *.iloc* no dataset, selecionando apenas as colunas do empr√©stimo e curso. Ao fazer um *value_counts()* neste resultado, vemos quantas vezes os anos e cursos apareceram no dataset.

![image](https://user-images.githubusercontent.com/67301805/236536166-f3e8c4a3-e678-481d-9839-50992cfb8157.png)

- Gerar uma tabela com os cursos como √≠ndice, as colunas s√£o os anos analisados (2015 a 2020) preenchidas com as quantidades de empr√©stimos e, ao final, acrescentar uma linha e coluna fazendo os somat√≥rios ‚úÖ

Eu nunca havia trabalhado com o *pivot_table* antes, quando li o desafio, pensei em resolver a atividade com um *crosstab*, por√©m gostei de aprender uma nova op√ß√£o para chegar em um resultado similar.

![image](https://user-images.githubusercontent.com/67301805/236536354-c369d6ec-261c-47ed-80c1-f946dcfd027d.png)


### Desafio 7: Customiza√ß√£o de tabelas

![07](https://user-images.githubusercontent.com/67301805/236515573-e132a360-850a-4e67-ae96-a0f5c420ab9c.jpg)

- Fazer a diferen√ßa percentual de empr√©stimos realizados (2017, 2018, 2019 e 2022) para cada curso

Fiz a importa√ß√£o dos arquivos Excel e JSON novamente, por√©m n√£o h√° registro de alunos de p√≥s gradua√ß√£o no primeiro arquivo, ent√£o vi necessidade de unir os dois, como fiz no come√ßo do desafio anterior.

Para fazer a sele√ß√£o dos anos, importei o arquivo *parquet* e fui fazendo *query*. Primeiro, com o tipo de aluno, depois com os anos (> 2017 e < 2020).




- Criar uma tabela com os valores encontrados



- Exportar como HTML


## Ferramentas utilizadas üß∞
<p> <a href="https://www.python.org" target="_blank" rel="noreferrer"> <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/python/python-original.svg" alt="python" width="40" height="40"/> </a> 
    <a href="https://pandas.pydata.org/" target="_blank" rel="noreferrer"> <img src="https://raw.githubusercontent.com/devicons/devicon/2ae2a900d2f041da66e950e4d48052658d850630/icons/pandas/pandas-original.svg" alt="pandas" width="40" height="40"/> </a>
    <a href="https://seaborn.pydata.org/" target="_blank" rel="noreferrer"> <img src="https://seaborn.pydata.org/_images/logo-mark-lightbg.svg" alt="seaborn" width="40" height="40"/> </a>
    </p>
